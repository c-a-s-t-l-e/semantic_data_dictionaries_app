[{"name": "app.py", "content": "from shiny import App, reactive, render, ui\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nimport re\nimport csv\n\ngroup_styles = \"\"\"\n.table-groups {\n    width: 100%;\n    border-collapse: collapse;\n    margin-bottom: 1rem;\n}\n.table-groups thead th {\n    background-color: #f8f9fa;\n    font-weight: bold;\n    border: 1px solid #ddd;\n    padding: 8px;\n}\n.table-groups tbody td {\n    border: 1px solid #ddd;\n    padding: 8px;\n}\n.table-groups tbody tr.group-1 td { background-color: rgba(255, 223, 223, 0.9); }\n.table-groups tbody tr.group-2 td { background-color: rgba(223, 255, 223, 0.9); }\n.table-groups tbody tr.group-3 td { background-color: rgba(223, 223, 255, 0.9); }\n.table-groups tbody tr.group-4 td { background-color: rgba(255, 255, 223, 0.9); }\n.table-groups tbody tr.group-5 td { background-color: rgba(255, 223, 255, 0.9); }\n.table-groups tbody tr.group-6 td { background-color: rgba(223, 255, 255, 0.9); }\n.table-groups tbody tr.group-7 td { background-color: rgba(255, 240, 223, 0.9); }\n.table-groups tbody tr.group-8 td { background-color: rgba(240, 223, 255, 0.9); }\n.table-groups tbody tr.group-9 td { background-color: rgba(223, 255, 240, 0.9); }\n.table-groups tbody tr.group-10 td { background-color: rgba(255, 223, 240, 0.9); }\n\"\"\"\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(group_styles)\n    ),\n    ui.layout_sidebar(\n        ui.sidebar(\n            ui.h4(\"Settings\"),\n            ui.input_file(\n                \"files\",\n                \"Upload CSV files\",\n                accept=[\".csv\"],\n                multiple=True\n            ),\n            ui.input_numeric(\"min_similarity\", \"Minimum Similarity Score (0-1)\", \n                           value=0.3, min=0, max=1, step=0.05),\n            ui.h4(\"Column Mappings\"),\n            ui.output_ui(\"column_selectors\"),\n            width=\"300px\"\n        ),\n        ui.card(\n            ui.h4(\"Uploaded Files\"),\n            ui.output_table(\"uploaded_files\"),\n        ),\n        ui.card(\n            ui.h4(\"Similar Column Groups\"),\n            ui.output_ui(\"similar_groups\"),\n        ),\n    )\n)\n\ndef server(input, output, session):\n    vectorizer = reactive.value(None)\n    file_columns = reactive.value({})\n    file_id_mapping = reactive.value({})\n    \n    def sanitize_id(filename):\n        sanitized = re.sub(r'[^a-zA-Z0-9_]', '_', filename)\n        if not sanitized[0].isalpha():\n            sanitized = 'f' + sanitized\n        return sanitized\n    \n    @reactive.effect\n    def _():\n        if vectorizer() is None:\n            vectorizer.set(TfidfVectorizer(\n                stop_words='english',\n                ngram_range=(1, 2),\n                min_df=1,\n                max_df=0.9\n            ))\n\n    @reactive.effect\n    def _update_file_columns():\n        files_info = input.files()\n        if files_info:\n            new_columns = {}\n            new_mapping = {}\n            for file_info in files_info:\n                try:\n                    try:\n                        df = pd.read_csv(file_info['datapath'])\n                    except pd.errors.ParserError:\n                        try:\n                            df = pd.read_csv(file_info['datapath'], quotechar='\"', escapechar='\\\\')\n                        except pd.errors.ParserError:\n                            df = pd.read_csv(file_info['datapath'], quoting=csv.QUOTE_NONE)\n                    \n                    filename = file_info['name']\n                    new_columns[filename] = list(df.columns)\n                    new_mapping[filename] = sanitize_id(filename)\n                except Exception as e:\n                    print(f\"Error reading file {file_info['name']}: {str(e)}\")\n                    continue\n            file_columns.set(new_columns)\n            file_id_mapping.set(new_mapping)\n\n    @render.ui\n    def column_selectors():\n        files_info = input.files()\n        if not files_info:\n            return ui.div()\n        \n        selectors = []\n        columns = file_columns()\n        id_mapping = file_id_mapping()\n        \n        for file_info in files_info:\n            filename = file_info['name']\n            if filename in columns and filename in id_mapping:\n                file_id = id_mapping[filename]\n                selectors.extend([\n                    ui.h5(filename),\n                    ui.input_select(\n                        f\"colname_{file_id}\",\n                        \"Column Name Column\",\n                        choices=columns[filename]\n                    ),\n                    ui.input_select(\n                        f\"coldesc_{file_id}\",\n                        \"Description Column\",\n                        choices=columns[filename]\n                    ),\n                    ui.tags.hr()\n                ])\n        \n        return ui.div(selectors)\n\n    @render.table\n    def uploaded_files():\n        files_info = input.files()\n        if not files_info or len(files_info) == 0:\n            return pd.DataFrame({\"Message\": [\"No files uploaded yet\"]})\n        \n        file_list = []\n        for file_info in files_info:\n            try:\n                try:\n                    df = pd.read_csv(file_info['datapath'])\n                except pd.errors.ParserError:\n                    try:\n                        df = pd.read_csv(file_info['datapath'], quotechar='\"', escapechar='\\\\')\n                    except pd.errors.ParserError:\n                        df = pd.read_csv(file_info['datapath'], quoting=csv.QUOTE_NONE)\n                \n                file_list.append({\n                    'Filename': file_info['name'],\n                    'Number of Columns': len(df.columns),\n                    'Status': 'Loaded successfully'\n                })\n            except Exception as e:\n                file_list.append({\n                    'Filename': file_info['name'],\n                    'Number of Columns': 0,\n                    'Status': f'Error: {str(e)}'\n                })\n        \n        return pd.DataFrame(file_list)\n    \n    def process_similar_groups():\n        files_info = input.files()\n        if not files_info or len(files_info) == 0:\n            return None\n        \n        all_columns = []\n        all_descriptions = []\n        sources = []\n        \n        id_mapping = file_id_mapping()\n        \n        for file_info in files_info:\n            try:\n                filename = file_info['name']\n                if filename not in id_mapping:\n                    continue\n                    \n                file_id = id_mapping[filename]\n                \n                try:\n                    df = pd.read_csv(file_info['datapath'])\n                except pd.errors.ParserError:\n                    try:\n                        df = pd.read_csv(file_info['datapath'], quotechar='\"', escapechar='\\\\')\n                    except pd.errors.ParserError:\n                        df = pd.read_csv(file_info['datapath'], quoting=csv.QUOTE_NONE)\n                \n                col_name = getattr(input, f\"colname_{file_id}\")()\n                col_desc = getattr(input, f\"coldesc_{file_id}\")()\n                \n                if not col_name or not col_desc:\n                    continue\n                \n                columns = df[col_name]\n                descriptions = df[col_desc]\n                \n                all_columns.extend(columns)\n                all_descriptions.extend(descriptions)\n                sources.extend([filename] * len(columns))\n            except Exception as e:\n                print(f\"Error processing file {filename}: {str(e)}\")\n                continue\n        \n        if not all_columns:\n            return None\n            \n        texts = [f\"{col.lower()} {desc.lower()}\" for col, desc in zip(all_columns, all_descriptions)]\n        \n        embeddings = vectorizer().fit_transform(texts)\n        similarity_matrix = cosine_similarity(embeddings)\n        \n        min_similarity = input.min_similarity()\n        used_indices = set()\n        \n        total_similarities = similarity_matrix.sum(axis=1)\n        sorted_indices = np.argsort(-total_similarities)\n        \n        result_rows = []\n        current_group = 1\n        \n        for i in sorted_indices:\n            if i in used_indices:\n                continue\n            \n            similar_mask = similarity_matrix[i] >= min_similarity\n            similar_indices = np.where(similar_mask)[0]\n            similar_indices = [j for j in similar_indices if j not in used_indices]\n            \n            if len(similar_indices) > 0:\n                result_rows.append({\n                    'Group': str(current_group),\n                    'group_num': current_group,\n                    'Similarity': 1.0,\n                    'Source': sources[i],\n                    'Column Name': all_columns[i],\n                    'Description': all_descriptions[i]\n                })\n                used_indices.add(i)\n                \n                for j in similar_indices:\n                    if j != i:\n                        result_rows.append({\n                            'Group': str(current_group),\n                            'group_num': current_group,\n                            'Similarity': similarity_matrix[i][j],\n                            'Source': sources[j],\n                            'Column Name': all_columns[j],\n                            'Description': all_descriptions[j]\n                        })\n                        used_indices.add(j)\n                \n                current_group += 1\n        \n        if not result_rows:\n            return None\n            \n        df = pd.DataFrame(result_rows)\n        df = df.sort_values(['group_num', 'Similarity'], ascending=[True, False])\n        return df\n\n    @render.ui\n    def similar_groups():\n        df = process_similar_groups()\n        if df is None:\n            return ui.HTML('<div class=\"alert alert-info\">Please upload data dictionary files and select columns</div>')\n    \n        df = df.copy()\n        # Convert similarity to numeric to ensure proper formatting\n        df['Similarity'] = pd.to_numeric(df['Similarity'])\n        # Format similarity as percentage with 1 decimal place\n        df['Similarity'] = df['Similarity'].apply(lambda x: f\"{x*100:.2f}\")\n    \n        table_html = '<div style=\"overflow-x: auto;\"><table class=\"table table-groups\">'\n        table_html += '<thead><tr><th>Group</th><th>Similarity</th><th>Source</th><th>Column Name</th><th>Description</th></tr></thead>'\n        table_html += '<tbody>'\n    \n        for _, row in df.iterrows():\n            group_num = row['group_num']\n            color_class = f\"group-{((group_num-1) % 10) + 1}\"\n            table_html += f'<tr class=\"{color_class}\">'\n            table_html += f'<td>{row[\"Group\"]}</td>'\n            table_html += f'<td>{row[\"Similarity\"]}</td>'\n            table_html += f'<td>{row[\"Source\"]}</td>'\n            table_html += f'<td>{row[\"Column Name\"]}</td>'\n            table_html += f'<td>{row[\"Description\"]}</td>'\n            table_html += '</tr>'\n    \n        table_html += '</tbody></table></div>'\n        return ui.HTML(table_html)\n\napp = App(app_ui, server)\n", "type": "text"}]